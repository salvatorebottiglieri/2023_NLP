{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE\n",
    "\n",
    "Using the Brown's \"Adventure\" category as your test set, compare it with the remaining part of the Brown dataset and check:\n",
    "* Vocabulary size difference. X\n",
    "* The intersection between the 100 most frequent words. X\n",
    "* Compare the most common Bigrams, with different measures\n",
    "* Do the same with trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate \"adventures\" category from all others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_categories = brown.categories()\n",
    "adventure_categories =other_categories.pop(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve file ids for every category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure_file_ids = brown.fileids(adventure_categories)\n",
    "other_categories_file_ids = []\n",
    "for category in other_categories:\n",
    "    for fids in brown.fileids(category):\n",
    "        other_categories_file_ids.append(fids)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every file ids, get the words and put in a set, obtaining a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure_vocabulary_words = set(brown.words(fileids=adventure_file_ids))\n",
    "other_vocabulary_words = set()\n",
    "for category_fids in other_categories_file_ids:\n",
    "        other_vocabulary_words=other_vocabulary_words.union(set(brown.words(fileids=category_fids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure_vocabulary_words: 8874\n",
      "other_vocabulary_words: 54339\n",
      "Vocabulary size difference: 45465\n"
     ]
    }
   ],
   "source": [
    "print(f\"adventure_vocabulary_words: {len(adventure_vocabulary_words)}\")\n",
    "print(f\"other_vocabulary_words: {len(other_vocabulary_words)}\")\n",
    "print(f\"Vocabulary size difference: {len(other_vocabulary_words)-len(adventure_vocabulary_words)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection between the 100 most frequent words\n",
    "\n",
    "### Get the word for \"adventures\" and other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adventure_words = brown.words(adventure_file_ids)\n",
    "other_categories_words = brown.words(other_categories_file_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filtering: remove puntuactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punctuations = set(string.punctuation)\n",
    "punctuations.add('``')\n",
    "punctuations.add('\\'\\'')\n",
    "\n",
    "adventure_words = [w for w in adventure_words if w not in punctuations]\n",
    "other_categories_words = [w for w in other_categories_words if w not in punctuations]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get frequency -> calculate intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'of', 'to', 'was', 'in', 'his', 'he', 'I', 'had', 'He', 'that', 'it', 'on', 'her', 'him', 'The', 'with', 'you', 'for', 'at', 'as', 'said', 'out', 'from', 'were', 'she', 'up', '--', 'me', 'they', 'this', 'but', 'would', 'be', 'into', 'not', 'my', 'all', 'man', 'one', 'an', 'their', 'them', 'could', 'by', 'It', 'like', 'have', 'there', 'been', 'time', 'when', 'no', 'But', 'about', 'over', 'or', 'so', 'what', 'which', 'then', 'only', 'is', 'do', 'who', 'if', 'now', 'we', 'did', 'more', 'before', 'two', 'A', 'made']\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "CAP_FREQUENCY = 100\n",
    "\n",
    "def brown_corpus_n_most_frequent_words(n,words):\n",
    "    frequency_distribution = FreqDist(words)\n",
    "    most_frequent_words = frequency_distribution.most_common(n)\n",
    "    return [word for word,_ in most_frequent_words]\n",
    "\n",
    "adventure_most_frequent_words = brown_corpus_n_most_frequent_words(CAP_FREQUENCY,adventure_words)\n",
    "other_categories_most_frequent_words = brown_corpus_n_most_frequent_words(CAP_FREQUENCY,other_categories_words)\n",
    "\n",
    "adv_other_frequent_words_intersection = [value for value in adventure_most_frequent_words \\\n",
    "                                        if value in other_categories_most_frequent_words]\n",
    "\n",
    "print(adv_other_frequent_words_intersection)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the most common Bigrams, with different measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI COMPARISON\n",
      "Adventure | Other\n",
      "('1', 'Europeans') | ('$10,000-per-year', 'French-born')\n",
      "(\"1890's\", 'Led') | ('$148.50', '2-4')\n",
      "('28', 'Attack') | ('$16', 'Participating')\n",
      "('600', 'fathoms') | ('$2,461,000', 'Inventories')\n",
      "('Aircraft', 'Identification') | ('$590,000', 'Apologies')\n",
      "('Alice', 'Rheumatics') | ('$79.89', 'nothing-down')\n",
      "(\"Allen's\", 'three-room') | ('$8.50', 'tab')\n",
      "('Anthropology', '6') | (\"'low\", 'nigras')\n",
      "('Association', 'meeting') | ('0.5-mv./m.', '50-percent')\n",
      "('Autos', 'whizzed') | ('0.78', 'mEq')\n"
     ]
    }
   ],
   "source": [
    "import nltk.collocations as collocations\n",
    "import string\n",
    "\n",
    "punctuations = list(string.punctuation)\n",
    "BEST_N_GRAMS = 10\n",
    "\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "adventure_bigrams = collocations.BigramCollocationFinder.from_words(adventure_words)\n",
    "other_bigrams = collocations.BigramCollocationFinder.from_words(other_categories_words)\n",
    "\n",
    "adventure_bigrams.apply_word_filter(lambda w: w.lower() in punctuations)\n",
    "other_bigrams.apply_word_filter(lambda w: w.lower() in punctuations)\n",
    "\n",
    "\n",
    "adventure_best_bmi = adventure_bigrams.nbest(bigram_measures.pmi,BEST_N_GRAMS)\n",
    "other_best_bmi = other_bigrams.nbest(bigram_measures.pmi,BEST_N_GRAMS)\n",
    "\n",
    "adventure_best_likelihood_ratio = adventure_bigrams.nbest(bigram_measures.likelihood_ratio,BEST_N_GRAMS)\n",
    "other_best_likelihood_ratio = other_bigrams.nbest(bigram_measures.likelihood_ratio,BEST_N_GRAMS)\n",
    "\n",
    "print(\"BMI COMPARISON\")\n",
    "print(\"Adventure | Other\")\n",
    "for i in range(BEST_N_GRAMS):\n",
    "    print(f\"{adventure_best_bmi[i]} | {other_best_bmi[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIKELIHOOD COMPARISON\n",
      "Adventure | Other\n",
      "('of', 'the') | ('of', 'the')\n",
      "('had', 'been') | ('in', 'the')\n",
      "('in', 'the') | ('the', 'the')\n",
      "('on', 'the') | ('United', 'States')\n",
      "('did', 'not') | ('to', 'be')\n",
      "('It', 'was') | ('on', 'the')\n",
      "('into', 'the') | ('had', 'been')\n",
      "('Miss', 'Langford') | ('New', 'York')\n",
      "('he', 'had') | ('have', 'been')\n",
      "('I', \"don't\") | ('has', 'been')\n"
     ]
    }
   ],
   "source": [
    "print(\"LIKELIHOOD COMPARISON\")\n",
    "print(\"Adventure | Other\")\n",
    "for i in range(BEST_N_GRAMS):\n",
    "    print(f\"{adventure_best_likelihood_ratio[i]} | {other_best_likelihood_ratio[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The same with Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI COMPARISON\n",
      "Adventure | Other\n",
      "(\"Allen's\", 'three-room', 'tarpapered') | ('$10,000-per-year', 'French-born', 'maitre')\n",
      "('Blessed', 'Saint', 'Nicholas') | ('060', 'Jean-Marie', 'LeClair')\n",
      "('Cigarette', 'butts', 'littered') | (\"2'\", 'Amenitskii', 'Noskova')\n",
      "('Gaston', 'Berche', 'crimsoning') | ('275-degrees-F', '135*0C.', 'Dryer')\n",
      "(\"Graves'\", 'imaginative', 'interpretation') | ('2:30-:36', 'Riverboat', 'Dalzell-Cousin')\n",
      "('Inc.', \"They'd\", 'peddled') | ('2:31', 'Armbro', 'Comet')\n",
      "('Jed', 'Hawkins', 'lives') | ('5-foot', '11-inch', 'headroom')\n",
      "(\"Nicolas's\", 'whereabouts', 'Packing') | ('871', '892', \"Alcinous'\")\n",
      "('Oil', 'Gas', 'Company') | ('Aiding', 'Leukemia', 'Stricken')\n",
      "('Raft', 'River', 'turnoff') | ('Alexei', 'Zhitkov', 'Lev')\n"
     ]
    }
   ],
   "source": [
    "trigram_measures = collocations.TrigramAssocMeasures()\n",
    "adventure_trigrams = collocations.TrigramCollocationFinder.from_words(adventure_words)\n",
    "other_trigrams = collocations.TrigramCollocationFinder.from_words(other_categories_words)\n",
    "\n",
    "adventure_trigrams.apply_word_filter(lambda w: w.lower() in punctuations)\n",
    "other_trigrams.apply_word_filter(lambda w: w.lower() in punctuations)\n",
    "\n",
    "adventure_best_bmi = adventure_trigrams.nbest(trigram_measures.pmi,BEST_N_GRAMS)\n",
    "other_best_bmi = other_trigrams.nbest(trigram_measures.pmi,BEST_N_GRAMS)\n",
    "\n",
    "adventure_best_likelihood_ratio = adventure_trigrams.nbest(trigram_measures.likelihood_ratio,BEST_N_GRAMS)\n",
    "other_best_likelihood_ratio = other_trigrams.nbest(trigram_measures.likelihood_ratio,BEST_N_GRAMS)\n",
    "\n",
    "print(\"BMI COMPARISON\")\n",
    "print(\"Adventure | Other\")\n",
    "for i in range(BEST_N_GRAMS):\n",
    "    print(f\"{adventure_best_bmi[i]} | {other_best_bmi[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIKELIHOOD COMPARISON\n",
      "Adventure | Other\n",
      "('out', 'of', 'the') | ('of', 'the', 'and')\n",
      "('he', 'had', 'been') | ('the', 'number', 'of')\n",
      "('of', 'the', 'hall') | ('the', 'is', 'of')\n",
      "('front', 'of', 'the') | ('the', 'first', 'of')\n",
      "('of', 'the', 'house') | ('of', 'the', 'same')\n",
      "('one', 'of', 'the') | ('the', 'most', 'of')\n",
      "('end', 'of', 'the') | ('the', 'part', 'of')\n",
      "('side', 'of', 'the') | ('the', 'kind', 'of')\n",
      "('He', 'had', 'been') | ('the', 'world', 'of')\n",
      "('of', 'the', 'street') | ('the', 'end', 'of')\n"
     ]
    }
   ],
   "source": [
    "print(\"LIKELIHOOD COMPARISON\")\n",
    "print(\"Adventure | Other\")\n",
    "for i in range(BEST_N_GRAMS):\n",
    "    print(f\"{adventure_best_likelihood_ratio[i]} | {other_best_likelihood_ratio[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d61932f3ec5a4495e1d1e1e23bab68247861fb8f817b7224c0745275bdd0d87f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
